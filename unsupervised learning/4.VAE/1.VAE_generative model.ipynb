{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB_V2ul2nzcI"
   },
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWC0ckWQCCJH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets,transforms\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AZUaWx-pdBk"
   },
   "source": [
    "초기 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGCDw5MaDECc"
   },
   "outputs": [],
   "source": [
    "image_path = './images'\n",
    "channels = 1                    # MNIST has only 1-흑백사진\n",
    "\n",
    "n_epochs = 30                   #학습 횟수\n",
    "batch_size = 128                #한번에 학습할 이미지 갯수\n",
    "lr = 1e-3                       #Learning rate\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "img_size = 28\n",
    "hidden_dim = 400\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-vMKKJXDJAX"
   },
   "outputs": [],
   "source": [
    "os.makedirs(image_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZtoosrPzyWn"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt_KMMA-phkZ"
   },
   "source": [
    "mnist train, test dataset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ym8CopDBNrK-"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "train = datasets.MNIST(root='./data/',train=True,transform=transform,download=True)\n",
    "test = datasets.MNIST(root='./data/',train=False,transform=transform,download=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q81N-mUkzARB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train[2][0][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNyh5KiMprKz"
   },
   "source": [
    "Encoder 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKf0cJoQoInH"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x_dim=img_size**2, h_dim=hidden_dim, z_dim=latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # 1st hidden layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "           #####빈칸을 채우세요######\n",
    "        )\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        self.fc2 = nn.Sequential(\n",
    "           #####빈칸을 채우세요######\n",
    "        )\n",
    "\n",
    "        # output layer\n",
    "        self.mu = nn.Linear(h_dim, z_dim)\n",
    "        self.logvar = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc2(self.fc1(x))\n",
    "\n",
    "        mu = F.relu(self.mu(x))\n",
    "        logvar = F.relu(self.logvar(x))\n",
    "\n",
    "        z = reparameterization(mu, logvar)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ0ps0pBp7pt"
   },
   "source": [
    "Decoder 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX-oVWILxmCW"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, x_dim=img_size**2, h_dim=hidden_dim, z_dim=latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # 1st hidden layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "           #####빈칸을 채우세요######\n",
    "        )\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        self.fc2 = nn.Sequential(\n",
    "           #####빈칸을 채우세요######\n",
    "        )\n",
    "\n",
    "        # output layer\n",
    "        self.fc3 = nn.Linear(h_dim, x_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc2(self.fc1(z))\n",
    "        x_reconst = F.sigmoid(self.fc3(z))\n",
    "        return x_reconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1dBG_GDXiO0"
   },
   "source": [
    "reparameterization 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRiLrIhHXflD"
   },
   "outputs": [],
   "source": [
    "def reparameterization(mu, logvar):\n",
    "    std = torch.exp(logvar/2)\n",
    "    eps = torch.randn_like(std)\n",
    "    return #####빈칸을 채우세요######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "En_aTzex4xkZ"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(encoder.parameters(), decoder.parameters()), lr=lr, betas=(b1, b2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696985336715,
     "user": {
      "displayName": "이승문",
      "userId": "17091695928167721952"
     },
     "user_tz": -540
    },
    "id": "aKGKA1gXTI7o",
    "outputId": "48d2e32a-3942-4a16-dcd3-5f41047d4746"
   },
   "outputs": [],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1696985337104,
     "user": {
      "displayName": "이승문",
      "userId": "17091695928167721952"
     },
     "user_tz": -540
    },
    "id": "hPRaMKpbTL0-",
    "outputId": "a009d97d-2ac7-4365-8c84-f87d96bc373f"
   },
   "outputs": [],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 732479,
     "status": "ok",
     "timestamp": 1696986070698,
     "user": {
      "displayName": "이승문",
      "userId": "17091695928167721952"
     },
     "user_tz": -540
    },
    "id": "usmbRBnL8NsL",
    "outputId": "d6b821c1-0271-441f-dd16-9e753fab130e"
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #Train\n",
    "    train_loss = 0\n",
    "    for i, (x, _) in enumerate(train_dataloader):\n",
    "        # forward\n",
    "        x = x.view(-1, img_size**2)\n",
    "        x = x.to(device)\n",
    "        z, mu, logvar = encoder(x)\n",
    "        x_reconst = decoder(z)\n",
    "\n",
    "        # compute reconstruction loss and KL divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
    "        kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "\n",
    "        # backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_dataloader)}], Reconst Loss : {reconst_loss.item():.4f}, KL Div: {kl_div.item():.4f}')\n",
    "\n",
    "    print(f'===> Epoch: {epoch+1} Average Train Loss: {train_loss/len(train_dataloader.dataset):.4f} ')\n",
    "    #Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_dataloader):\n",
    "            # forward\n",
    "            x = x.view(-1, img_size**2)\n",
    "            x = x.to(device)\n",
    "            z, mu, logvar = encoder(x)\n",
    "            x_reconst = decoder(z)\n",
    "\n",
    "            # compute reconstruction loss and KL divergence\n",
    "            reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
    "            kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "\n",
    "            loss = reconst_loss + kl_div\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # save reconstruction images\n",
    "            if i==0:\n",
    "                x_concat = torch.cat([x.view(-1, 1, 28, 28), x_reconst.view(-1, 1, 28, 28)], dim=3)\n",
    "                # batch size 개수만큼의 이미지 쌍(input x, reconstructed x)이 저장됨\n",
    "                save_image(x_concat, os.path.join(image_path,f'reconst-epoch{epoch+1}.png'))\n",
    "\n",
    "        print(f'===> Epoch: {epoch+1} Average Test Loss: {test_loss/len(test_dataloader.dataset):.4f} ')\n",
    "\n",
    "        # save sampled images\n",
    "        z = torch.randn(batch_size, latent_dim).to(device) # N(0, 1)에서 z 샘플링\n",
    "        sampled_images = decoder(z)\n",
    "        save_image(sampled_images.view(-1, 1, 28, 28), os.path.join(image_path,f'sampled-epoch{epoch+1}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1PlI2kvxAOH3BD3HvgAdCX6MWlAiB-S96",
     "timestamp": 1693459599943
    },
    {
     "file_id": "11PaOMTiwaLUrb2N9_5rNVHA5AF4IRhh1",
     "timestamp": 1657520159122
    },
    {
     "file_id": "1CvST-AI7NKuYh5p-OZpMWKNqI19T28LG",
     "timestamp": 1657439802308
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
