{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB_V2ul2nzcI"
   },
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aWC0ckWQCCJH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets,transforms\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AZUaWx-pdBk"
   },
   "source": [
    "초기 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qGCDw5MaDECc"
   },
   "outputs": [],
   "source": [
    "image_path = './images'\n",
    "channels = 1                    # MNIST has only 1-흑백사진\n",
    "\n",
    "n_epochs = 10                   #학습 횟수\n",
    "batch_size = 128                #한번에 학습할 이미지 갯수\n",
    "lr = 1e-3                       #Learning rate\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "img_size = 28\n",
    "hidden_dim = 400\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P-vMKKJXDJAX"
   },
   "outputs": [],
   "source": [
    "os.makedirs(image_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QZtoosrPzyWn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt_KMMA-phkZ"
   },
   "source": [
    "mnist train, test dataset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ym8CopDBNrK-"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "train = datasets.MNIST(root='./data/',train=True,transform=transform,download=True)\n",
    "test = datasets.MNIST(root='./data/',train=False,transform=transform,download=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q81N-mUkzARB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fc6a8639d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train[2][0][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNyh5KiMprKz"
   },
   "source": [
    "Encoder 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AKf0cJoQoInH"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x_dim=img_size**2, h_dim=hidden_dim, z_dim=latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # 1st hidden layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(x_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        # output layer\n",
    "        self.mu = nn.Linear(h_dim, z_dim)\n",
    "        self.logvar = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc2(self.fc1(x))\n",
    "\n",
    "        mu = F.relu(self.mu(x))\n",
    "        logvar = F.relu(self.logvar(x))\n",
    "\n",
    "        z = reparameterization(mu, logvar)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ0ps0pBp7pt"
   },
   "source": [
    "Decoder 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EX-oVWILxmCW"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, x_dim=img_size**2, h_dim=hidden_dim, z_dim=latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # 1st hidden layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        # output layer\n",
    "        self.fc3 = nn.Linear(h_dim, x_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc2(self.fc1(z))\n",
    "        x_reconst = F.sigmoid(self.fc3(z))\n",
    "        return x_reconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1dBG_GDXiO0"
   },
   "source": [
    "reparameterization 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dRiLrIhHXflD"
   },
   "outputs": [],
   "source": [
    "def reparameterization(mu, logvar):\n",
    "    std = torch.exp(logvar/2)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "En_aTzex4xkZ"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(encoder.parameters(), decoder.parameters()), lr=lr, betas=(b1, b2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696985336715,
     "user": {
      "displayName": "이승문",
      "userId": "17091695928167721952"
     },
     "user_tz": -540
    },
    "id": "aKGKA1gXTI7o",
    "outputId": "48d2e32a-3942-4a16-dcd3-5f41047d4746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (mu): Linear(in_features=400, out_features=10, bias=True)\n",
      "  (logvar): Linear(in_features=400, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1696985337104,
     "user": {
      "displayName": "이승문",
      "userId": "17091695928167721952"
     },
     "user_tz": -540
    },
    "id": "hPRaMKpbTL0-",
    "outputId": "a009d97d-2ac7-4365-8c84-f87d96bc373f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fc3): Linear(in_features=400, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 732479,
     "status": "ok",
     "timestamp": 1696986070698,
     "user": {
      "displayName": "이승문",
      "userId": "17091695928167721952"
     },
     "user_tz": -540
    },
    "id": "usmbRBnL8NsL",
    "outputId": "d6b821c1-0271-441f-dd16-9e753fab130e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/469], Reconst Loss : 29233.3105, KL Div: 852.7147\n",
      "Epoch [1/10], Step [20/469], Reconst Loss : 27566.8320, KL Div: 415.6074\n",
      "Epoch [1/10], Step [30/469], Reconst Loss : 26731.3457, KL Div: 180.0115\n",
      "Epoch [1/10], Step [40/469], Reconst Loss : 26596.7578, KL Div: 211.0909\n",
      "Epoch [1/10], Step [50/469], Reconst Loss : 25515.4121, KL Div: 340.7745\n",
      "Epoch [1/10], Step [60/469], Reconst Loss : 26105.2852, KL Div: 418.9705\n",
      "Epoch [1/10], Step [70/469], Reconst Loss : 25790.3633, KL Div: 270.9810\n",
      "Epoch [1/10], Step [80/469], Reconst Loss : 25291.1484, KL Div: 356.6006\n",
      "Epoch [1/10], Step [90/469], Reconst Loss : 25844.9199, KL Div: 283.8730\n",
      "Epoch [1/10], Step [100/469], Reconst Loss : 25475.3398, KL Div: 422.2252\n",
      "Epoch [1/10], Step [110/469], Reconst Loss : 26009.5938, KL Div: 384.5183\n",
      "Epoch [1/10], Step [120/469], Reconst Loss : 25221.0781, KL Div: 451.5322\n",
      "Epoch [1/10], Step [130/469], Reconst Loss : 25330.2383, KL Div: 462.7078\n",
      "Epoch [1/10], Step [140/469], Reconst Loss : 24707.6992, KL Div: 603.2718\n",
      "Epoch [1/10], Step [150/469], Reconst Loss : 24015.6758, KL Div: 605.5812\n",
      "Epoch [1/10], Step [160/469], Reconst Loss : 25352.1523, KL Div: 470.8535\n",
      "Epoch [1/10], Step [170/469], Reconst Loss : 23887.9023, KL Div: 512.1361\n",
      "Epoch [1/10], Step [180/469], Reconst Loss : 23619.7812, KL Div: 692.0642\n",
      "Epoch [1/10], Step [190/469], Reconst Loss : 24056.8945, KL Div: 699.5663\n",
      "Epoch [1/10], Step [200/469], Reconst Loss : 24630.5820, KL Div: 769.1562\n",
      "Epoch [1/10], Step [210/469], Reconst Loss : 23341.5898, KL Div: 796.7988\n",
      "Epoch [1/10], Step [220/469], Reconst Loss : 23427.7539, KL Div: 642.5753\n",
      "Epoch [1/10], Step [230/469], Reconst Loss : 23630.6328, KL Div: 893.6951\n",
      "Epoch [1/10], Step [240/469], Reconst Loss : 24155.2344, KL Div: 844.5269\n",
      "Epoch [1/10], Step [250/469], Reconst Loss : 23246.8086, KL Div: 846.7659\n",
      "Epoch [1/10], Step [260/469], Reconst Loss : 23362.9746, KL Div: 878.9108\n",
      "Epoch [1/10], Step [270/469], Reconst Loss : 22810.7031, KL Div: 848.7650\n",
      "Epoch [1/10], Step [280/469], Reconst Loss : 22857.7520, KL Div: 917.4538\n",
      "Epoch [1/10], Step [290/469], Reconst Loss : 22931.8652, KL Div: 917.3826\n",
      "Epoch [1/10], Step [300/469], Reconst Loss : 23684.4551, KL Div: 866.8541\n",
      "Epoch [1/10], Step [310/469], Reconst Loss : 21533.9707, KL Div: 998.3475\n",
      "Epoch [1/10], Step [320/469], Reconst Loss : 22610.7227, KL Div: 1239.7830\n",
      "Epoch [1/10], Step [330/469], Reconst Loss : 22066.7207, KL Div: 1063.8900\n",
      "Epoch [1/10], Step [340/469], Reconst Loss : 22735.4258, KL Div: 1138.4709\n",
      "Epoch [1/10], Step [350/469], Reconst Loss : 22271.7754, KL Div: 1102.2979\n",
      "Epoch [1/10], Step [360/469], Reconst Loss : 21704.9766, KL Div: 1016.1424\n",
      "Epoch [1/10], Step [370/469], Reconst Loss : 22217.8691, KL Div: 1126.9246\n",
      "Epoch [1/10], Step [380/469], Reconst Loss : 22586.6914, KL Div: 1346.3396\n",
      "Epoch [1/10], Step [390/469], Reconst Loss : 22044.9902, KL Div: 1306.8120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m z, mu, logvar \u001b[38;5;241m=\u001b[39m encoder(x)\n\u001b[1;32m----> 9\u001b[0m x_reconst \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# compute reconstruction loss and KL divergence\u001b[39;00m\n\u001b[0;32m     12\u001b[0m reconst_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(x_reconst, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\LGch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\LGch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[0;32m     23\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(z))\n\u001b[1;32m---> 24\u001b[0m     x_reconst \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_reconst\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\LGch\\lib\\site-packages\\torch\\nn\\functional.py:1981\u001b[0m, in \u001b[0;36msigmoid\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m   1974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"sigmoid(input) -> Tensor\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \n\u001b[0;32m   1977\u001b[0m \u001b[38;5;124;03m    Applies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\u001b[39;00m\n\u001b[0;32m   1978\u001b[0m \n\u001b[0;32m   1979\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.nn.Sigmoid` for more details.\u001b[39;00m\n\u001b[0;32m   1980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #Train\n",
    "    train_loss = 0\n",
    "    for i, (x, _) in enumerate(train_dataloader):\n",
    "        # forward\n",
    "        x = x.view(-1, img_size**2)\n",
    "        x = x.to(device)\n",
    "        z, mu, logvar = encoder(x)\n",
    "        x_reconst = decoder(z)\n",
    "\n",
    "        # compute reconstruction loss and KL divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
    "        kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "\n",
    "        # backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_dataloader)}], Reconst Loss : {reconst_loss.item():.4f}, KL Div: {kl_div.item():.4f}')\n",
    "\n",
    "    print(f'===> Epoch: {epoch+1} Average Train Loss: {train_loss/len(train_dataloader.dataset):.4f} ')\n",
    "    #Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_dataloader):\n",
    "            # forward\n",
    "            x = x.view(-1, img_size**2)\n",
    "            x = x.to(device)\n",
    "            z, mu, logvar = encoder(x)\n",
    "            x_reconst = decoder(z)\n",
    "\n",
    "            # compute reconstruction loss and KL divergence\n",
    "            reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
    "            kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "\n",
    "            loss = reconst_loss + kl_div\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # save reconstruction images\n",
    "            if i==0:\n",
    "                x_concat = torch.cat([x.view(-1, 1, 28, 28), x_reconst.view(-1, 1, 28, 28)], dim=3)\n",
    "                # batch size 개수만큼의 이미지 쌍(input x, reconstructed x)이 저장됨\n",
    "                save_image(x_concat, os.path.join(image_path,f'reconst-epoch{epoch+1}.png'))\n",
    "\n",
    "        print(f'===> Epoch: {epoch+1} Average Test Loss: {test_loss/len(test_dataloader.dataset):.4f} ')\n",
    "\n",
    "        # save sampled images\n",
    "        z = torch.randn(batch_size, latent_dim).to(device) # N(0, 1)에서 z 샘플링\n",
    "        sampled_images = decoder(z)\n",
    "        save_image(sampled_images.view(-1, 1, 28, 28), os.path.join(image_path,f'sampled-epoch{epoch+1}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1PlI2kvxAOH3BD3HvgAdCX6MWlAiB-S96",
     "timestamp": 1693459599943
    },
    {
     "file_id": "11PaOMTiwaLUrb2N9_5rNVHA5AF4IRhh1",
     "timestamp": 1657520159122
    },
    {
     "file_id": "1CvST-AI7NKuYh5p-OZpMWKNqI19T28LG",
     "timestamp": 1657439802308
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
